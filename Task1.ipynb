{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ./audio_files/test_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved frame: ./frames/test_video\\frame_0.jpg\n",
      "Saved frame: ./frames/test_video\\frame_1.jpg\n",
      "Saved frame: ./frames/test_video\\frame_2.jpg\n",
      "Saved frame: ./frames/test_video\\frame_3.jpg\n",
      "Saved frame: ./frames/test_video\\frame_4.jpg\n",
      "Saved frame: ./frames/test_video\\frame_5.jpg\n",
      "Saved frame: ./frames/test_video\\frame_6.jpg\n",
      "Saved frame: ./frames/test_video\\frame_7.jpg\n",
      "Saved frame: ./frames/test_video\\frame_8.jpg\n",
      "Saved frame: ./frames/test_video\\frame_9.jpg\n",
      "Saved frame: ./frames/test_video\\frame_10.jpg\n",
      "Saved frame: ./frames/test_video\\frame_11.jpg\n",
      "Saved frame: ./frames/test_video\\frame_12.jpg\n",
      "Saved frame: ./frames/test_video\\frame_13.jpg\n",
      "Saved frame: ./frames/test_video\\frame_14.jpg\n",
      "Saved frame: ./frames/test_video\\frame_15.jpg\n",
      "Saved frame: ./frames/test_video\\frame_16.jpg\n",
      "Saved frame: ./frames/test_video\\frame_17.jpg\n",
      "Saved frame: ./frames/test_video\\frame_18.jpg\n",
      "Saved frame: ./frames/test_video\\frame_19.jpg\n",
      "Saved frame: ./frames/test_video\\frame_20.jpg\n",
      "Saved frame: ./frames/test_video\\frame_21.jpg\n",
      "Saved frame: ./frames/test_video\\frame_22.jpg\n",
      "Saved frame: ./frames/test_video\\frame_23.jpg\n",
      "Saved frame: ./frames/test_video\\frame_24.jpg\n",
      "Saved frame: ./frames/test_video\\frame_25.jpg\n",
      "Saved frame: ./frames/test_video\\frame_26.jpg\n",
      "Saved frame: ./frames/test_video\\frame_27.jpg\n",
      "Saved frame: ./frames/test_video\\frame_28.jpg\n",
      "Saved frame: ./frames/test_video\\frame_29.jpg\n",
      "Saved frame: ./frames/test_video\\frame_30.jpg\n",
      "Saved frame: ./frames/test_video\\frame_31.jpg\n",
      "Saved frame: ./frames/test_video\\frame_32.jpg\n",
      "Saved frame: ./frames/test_video\\frame_33.jpg\n",
      "Saved frame: ./frames/test_video\\frame_34.jpg\n",
      "Saved frame: ./frames/test_video\\frame_35.jpg\n",
      "Saved frame: ./frames/test_video\\frame_36.jpg\n",
      "Saved frame: ./frames/test_video\\frame_37.jpg\n",
      "Saved frame: ./frames/test_video\\frame_38.jpg\n",
      "Saved frame: ./frames/test_video\\frame_39.jpg\n",
      "Saved frame: ./frames/test_video\\frame_40.jpg\n",
      "Saved frame: ./frames/test_video\\frame_41.jpg\n",
      "Saved frame: ./frames/test_video\\frame_42.jpg\n",
      "Saved frame: ./frames/test_video\\frame_43.jpg\n",
      "Saved frame: ./frames/test_video\\frame_44.jpg\n",
      "Saved frame: ./frames/test_video\\frame_45.jpg\n",
      "Saved frame: ./frames/test_video\\frame_46.jpg\n",
      "Saved frame: ./frames/test_video\\frame_47.jpg\n",
      "Saved frame: ./frames/test_video\\frame_48.jpg\n",
      "Saved frame: ./frames/test_video\\frame_49.jpg\n",
      "Saved frame: ./frames/test_video\\frame_50.jpg\n",
      "Saved frame: ./frames/test_video\\frame_51.jpg\n",
      "Saved frame: ./frames/test_video\\frame_52.jpg\n",
      "Saved frame: ./frames/test_video\\frame_53.jpg\n",
      "Saved frame: ./frames/test_video\\frame_54.jpg\n",
      "Saved frame: ./frames/test_video\\frame_55.jpg\n",
      "Saved frame: ./frames/test_video\\frame_56.jpg\n",
      "Saved frame: ./frames/test_video\\frame_57.jpg\n",
      "Saved frame: ./frames/test_video\\frame_58.jpg\n",
      "Saved frame: ./frames/test_video\\frame_59.jpg\n",
      "Saved frame: ./frames/test_video\\frame_60.jpg\n",
      "Saved frame: ./frames/test_video\\frame_61.jpg\n",
      "Saved frame: ./frames/test_video\\frame_62.jpg\n",
      "Saved frame: ./frames/test_video\\frame_63.jpg\n",
      "Saved frame: ./frames/test_video\\frame_64.jpg\n",
      "Saved frame: ./frames/test_video\\frame_65.jpg\n",
      "Saved frame: ./frames/test_video\\frame_66.jpg\n",
      "Saved frame: ./frames/test_video\\frame_67.jpg\n",
      "Saved frame: ./frames/test_video\\frame_68.jpg\n",
      "Saved frame: ./frames/test_video\\frame_69.jpg\n",
      "Saved frame: ./frames/test_video\\frame_70.jpg\n",
      "Saved frame: ./frames/test_video\\frame_71.jpg\n",
      "Saved frame: ./frames/test_video\\frame_72.jpg\n",
      "Saved frame: ./frames/test_video\\frame_73.jpg\n",
      "Saved frame: ./frames/test_video\\frame_74.jpg\n",
      "Saved frame: ./frames/test_video\\frame_75.jpg\n",
      "Saved frame: ./frames/test_video\\frame_76.jpg\n",
      "Saved frame: ./frames/test_video\\frame_77.jpg\n",
      "Saved frame: ./frames/test_video\\frame_78.jpg\n",
      "Saved frame: ./frames/test_video\\frame_79.jpg\n",
      "Saved frame: ./frames/test_video\\frame_80.jpg\n",
      "Saved frame: ./frames/test_video\\frame_81.jpg\n",
      "Saved frame: ./frames/test_video\\frame_82.jpg\n",
      "Saved frame: ./frames/test_video\\frame_83.jpg\n",
      "Saved frame: ./frames/test_video\\frame_84.jpg\n",
      "Saved frame: ./frames/test_video\\frame_85.jpg\n",
      "Saved frame: ./frames/test_video\\frame_86.jpg\n",
      "Saved frame: ./frames/test_video\\frame_87.jpg\n",
      "Saved frame: ./frames/test_video\\frame_88.jpg\n",
      "Saved frame: ./frames/test_video\\frame_89.jpg\n",
      "Saved frame: ./frames/test_video\\frame_90.jpg\n",
      "Saved frame: ./frames/test_video\\frame_91.jpg\n",
      "Saved frame: ./frames/test_video\\frame_92.jpg\n",
      "Saved frame: ./frames/test_video\\frame_93.jpg\n",
      "Saved frame: ./frames/test_video\\frame_94.jpg\n",
      "Saved frame: ./frames/test_video\\frame_95.jpg\n",
      "Saved frame: ./frames/test_video\\frame_96.jpg\n",
      "Saved frame: ./frames/test_video\\frame_97.jpg\n",
      "Saved frame: ./frames/test_video\\frame_98.jpg\n",
      "Saved frame: ./frames/test_video\\frame_99.jpg\n",
      "Saved frame: ./frames/test_video\\frame_100.jpg\n",
      "Saved frame: ./frames/test_video\\frame_101.jpg\n",
      "Saved frame: ./frames/test_video\\frame_102.jpg\n",
      "Saved frame: ./frames/test_video\\frame_103.jpg\n",
      "Saved frame: ./frames/test_video\\frame_104.jpg\n",
      "Saved frame: ./frames/test_video\\frame_105.jpg\n",
      "Saved frame: ./frames/test_video\\frame_106.jpg\n",
      "Saved frame: ./frames/test_video\\frame_107.jpg\n",
      "Saved frame: ./frames/test_video\\frame_108.jpg\n",
      "Saved frame: ./frames/test_video\\frame_109.jpg\n",
      "Saved frame: ./frames/test_video\\frame_110.jpg\n",
      "Saved frame: ./frames/test_video\\frame_111.jpg\n",
      "Saved frame: ./frames/test_video\\frame_112.jpg\n",
      "Saved frame: ./frames/test_video\\frame_113.jpg\n",
      "Saved frame: ./frames/test_video\\frame_114.jpg\n",
      "Saved frame: ./frames/test_video\\frame_115.jpg\n",
      "Saved frame: ./frames/test_video\\frame_116.jpg\n",
      "Saved frame: ./frames/test_video\\frame_117.jpg\n",
      "Saved frame: ./frames/test_video\\frame_118.jpg\n",
      "Saved frame: ./frames/test_video\\frame_119.jpg\n",
      "Saved frame: ./frames/test_video\\frame_120.jpg\n",
      "Saved frame: ./frames/test_video\\frame_121.jpg\n",
      "Saved frame: ./frames/test_video\\frame_122.jpg\n",
      "Saved frame: ./frames/test_video\\frame_123.jpg\n",
      "Saved frame: ./frames/test_video\\frame_124.jpg\n",
      "Saved frame: ./frames/test_video\\frame_125.jpg\n",
      "Saved frame: ./frames/test_video\\frame_126.jpg\n",
      "Saved frame: ./frames/test_video\\frame_127.jpg\n",
      "Saved frame: ./frames/test_video\\frame_128.jpg\n",
      "Saved frame: ./frames/test_video\\frame_129.jpg\n",
      "Saved frame: ./frames/test_video\\frame_130.jpg\n",
      "Saved frame: ./frames/test_video\\frame_131.jpg\n",
      "Saved frame: ./frames/test_video\\frame_132.jpg\n",
      "Saved frame: ./frames/test_video\\frame_133.jpg\n",
      "Saved frame: ./frames/test_video\\frame_134.jpg\n",
      "Saved frame: ./frames/test_video\\frame_135.jpg\n",
      "Saved frame: ./frames/test_video\\frame_136.jpg\n",
      "Saved frame: ./frames/test_video\\frame_137.jpg\n",
      "Saved frame: ./frames/test_video\\frame_138.jpg\n",
      "Saved frame: ./frames/test_video\\frame_139.jpg\n",
      "Saved frame: ./frames/test_video\\frame_140.jpg\n",
      "Saved frame: ./frames/test_video\\frame_141.jpg\n",
      "Saved frame: ./frames/test_video\\frame_142.jpg\n",
      "Saved frame: ./frames/test_video\\frame_143.jpg\n",
      "Saved frame: ./frames/test_video\\frame_144.jpg\n",
      "Saved frame: ./frames/test_video\\frame_145.jpg\n",
      "Saved frame: ./frames/test_video\\frame_146.jpg\n",
      "Saved frame: ./frames/test_video\\frame_147.jpg\n",
      "Saved frame: ./frames/test_video\\frame_148.jpg\n",
      "Saved frame: ./frames/test_video\\frame_149.jpg\n",
      "Saved frame: ./frames/test_video\\frame_150.jpg\n",
      "Saved frame: ./frames/test_video\\frame_151.jpg\n",
      "Saved frame: ./frames/test_video\\frame_152.jpg\n",
      "Saved frame: ./frames/test_video\\frame_153.jpg\n",
      "Saved frame: ./frames/test_video\\frame_154.jpg\n",
      "Saved frame: ./frames/test_video\\frame_155.jpg\n",
      "Saved frame: ./frames/test_video\\frame_156.jpg\n",
      "Saved frame: ./frames/test_video\\frame_157.jpg\n",
      "Saved frame: ./frames/test_video\\frame_158.jpg\n",
      "Saved frame: ./frames/test_video\\frame_159.jpg\n",
      "Saved frame: ./frames/test_video\\frame_160.jpg\n",
      "Saved frame: ./frames/test_video\\frame_161.jpg\n",
      "Saved frame: ./frames/test_video\\frame_162.jpg\n",
      "Saved frame: ./frames/test_video\\frame_163.jpg\n",
      "Saved frame: ./frames/test_video\\frame_164.jpg\n",
      "Saved frame: ./frames/test_video\\frame_165.jpg\n",
      "Saved frame: ./frames/test_video\\frame_166.jpg\n",
      "Saved frame: ./frames/test_video\\frame_167.jpg\n",
      "Saved frame: ./frames/test_video\\frame_168.jpg\n",
      "Saved frame: ./frames/test_video\\frame_169.jpg\n",
      "Saved frame: ./frames/test_video\\frame_170.jpg\n",
      "Saved frame: ./frames/test_video\\frame_171.jpg\n",
      "Saved frame: ./frames/test_video\\frame_172.jpg\n",
      "Saved frame: ./frames/test_video\\frame_173.jpg\n",
      "Saved frame: ./frames/test_video\\frame_174.jpg\n",
      "Saved frame: ./frames/test_video\\frame_175.jpg\n",
      "Saved frame: ./frames/test_video\\frame_176.jpg\n",
      "Saved frame: ./frames/test_video\\frame_177.jpg\n",
      "Saved frame: ./frames/test_video\\frame_178.jpg\n",
      "Saved frame: ./frames/test_video\\frame_179.jpg\n",
      "Saved frame: ./frames/test_video\\frame_180.jpg\n",
      "Saved frame: ./frames/test_video\\frame_181.jpg\n",
      "Saved frame: ./frames/test_video\\frame_182.jpg\n",
      "Saved frame: ./frames/test_video\\frame_183.jpg\n",
      "Saved frame: ./frames/test_video\\frame_184.jpg\n",
      "Saved frame: ./frames/test_video\\frame_185.jpg\n",
      "Saved frame: ./frames/test_video\\frame_186.jpg\n",
      "Saved frame: ./frames/test_video\\frame_187.jpg\n",
      "Saved frame: ./frames/test_video\\frame_188.jpg\n",
      "Saved frame: ./frames/test_video\\frame_189.jpg\n",
      "Saved frame: ./frames/test_video\\frame_190.jpg\n",
      "Saved frame: ./frames/test_video\\frame_191.jpg\n",
      "Saved frame: ./frames/test_video\\frame_192.jpg\n",
      "Saved frame: ./frames/test_video\\frame_193.jpg\n",
      "Saved frame: ./frames/test_video\\frame_194.jpg\n",
      "Saved frame: ./frames/test_video\\frame_195.jpg\n",
      "Saved frame: ./frames/test_video\\frame_196.jpg\n",
      "Saved frame: ./frames/test_video\\frame_197.jpg\n",
      "Saved frame: ./frames/test_video\\frame_198.jpg\n",
      "Saved frame: ./frames/test_video\\frame_199.jpg\n",
      "Saved frame: ./frames/test_video\\frame_200.jpg\n",
      "Saved frame: ./frames/test_video\\frame_201.jpg\n",
      "Saved frame: ./frames/test_video\\frame_202.jpg\n",
      "Saved frame: ./frames/test_video\\frame_203.jpg\n",
      "Saved frame: ./frames/test_video\\frame_204.jpg\n",
      "Saved frame: ./frames/test_video\\frame_205.jpg\n",
      "Saved frame: ./frames/test_video\\frame_206.jpg\n",
      "Saved frame: ./frames/test_video\\frame_207.jpg\n",
      "Saved frame: ./frames/test_video\\frame_208.jpg\n",
      "Saved frame: ./frames/test_video\\frame_209.jpg\n",
      "Saved frame: ./frames/test_video\\frame_210.jpg\n",
      "Saved frame: ./frames/test_video\\frame_211.jpg\n",
      "Saved frame: ./frames/test_video\\frame_212.jpg\n",
      "Saved frame: ./frames/test_video\\frame_213.jpg\n",
      "Saved frame: ./frames/test_video\\frame_214.jpg\n",
      "Saved frame: ./frames/test_video\\frame_215.jpg\n",
      "Saved frame: ./frames/test_video\\frame_216.jpg\n",
      "Saved frame: ./frames/test_video\\frame_217.jpg\n",
      "Saved frame: ./frames/test_video\\frame_218.jpg\n",
      "Saved frame: ./frames/test_video\\frame_219.jpg\n",
      "Saved frame: ./frames/test_video\\frame_220.jpg\n",
      "Saved frame: ./frames/test_video\\frame_221.jpg\n",
      "Saved frame: ./frames/test_video\\frame_222.jpg\n",
      "Saved frame: ./frames/test_video\\frame_223.jpg\n",
      "Saved frame: ./frames/test_video\\frame_224.jpg\n",
      "Saved frame: ./frames/test_video\\frame_225.jpg\n",
      "Saved frame: ./frames/test_video\\frame_226.jpg\n",
      "Saved frame: ./frames/test_video\\frame_227.jpg\n",
      "Saved frame: ./frames/test_video\\frame_228.jpg\n",
      "Saved frame: ./frames/test_video\\frame_229.jpg\n",
      "Saved frame: ./frames/test_video\\frame_230.jpg\n",
      "Saved frame: ./frames/test_video\\frame_231.jpg\n",
      "Saved frame: ./frames/test_video\\frame_232.jpg\n",
      "Saved frame: ./frames/test_video\\frame_233.jpg\n",
      "Saved frame: ./frames/test_video\\frame_234.jpg\n",
      "Saved frame: ./frames/test_video\\frame_235.jpg\n",
      "Saved frame: ./frames/test_video\\frame_236.jpg\n",
      "Saved frame: ./frames/test_video\\frame_237.jpg\n",
      "Saved frame: ./frames/test_video\\frame_238.jpg\n",
      "Saved frame: ./frames/test_video\\frame_239.jpg\n",
      "Saved frame: ./frames/test_video\\frame_240.jpg\n",
      "Saved frame: ./frames/test_video\\frame_241.jpg\n",
      "Saved frame: ./frames/test_video\\frame_242.jpg\n",
      "Saved frame: ./frames/test_video\\frame_243.jpg\n",
      "Saved frame: ./frames/test_video\\frame_244.jpg\n",
      "Saved frame: ./frames/test_video\\frame_245.jpg\n",
      "Saved frame: ./frames/test_video\\frame_246.jpg\n",
      "Saved frame: ./frames/test_video\\frame_247.jpg\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Функция для извлечения аудио из видео\n",
    "def extract_audio_from_video(video_path, output_audio_path):\n",
    "    video = mp.VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile(output_audio_path)\n",
    "\n",
    "# Функция для нарезки видео на фреймы\n",
    "def extract_frames_from_video(video_path, output_frames_dir, frame_rate=1):\n",
    "    # Создаём директорию для сохранения фреймов, если её нет\n",
    "    os.makedirs(output_frames_dir, exist_ok=True)\n",
    "    \n",
    "    # Открываем видео\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    \n",
    "    count = 0\n",
    "    while success:\n",
    "        # Сохраняем каждый кадр через указанное количество фреймов (например, 1 кадр в секунду)\n",
    "        if count % frame_rate == 0:\n",
    "            frame_filename = os.path.join(output_frames_dir, f\"frame_{count}.jpg\")\n",
    "            cv2.imwrite(frame_filename, image)  # Сохраняем кадр\n",
    "            print(f'Saved frame: {frame_filename}')\n",
    "        \n",
    "        success, image = vidcap.read()  # Читаем следующий кадр\n",
    "        count += 1\n",
    "    \n",
    "    vidcap.release()\n",
    "\n",
    "# Путь к вашему видеофайлу MP4\n",
    "video_path = \"./videos/video10.mp4\"\n",
    "\n",
    "# Путь для сохранения аудио в формате WAV\n",
    "output_audio_path = \"./audio_files/test_audio.wav\"\n",
    "\n",
    "# Директория для сохранения фреймов\n",
    "output_frames_dir = \"./frames/test_video\"\n",
    "\n",
    "# Извлечение аудио из видео\n",
    "extract_audio_from_video(video_path, output_audio_path)\n",
    "\n",
    "# Нарезка видео на фреймы (1 кадр в секунду)\n",
    "extract_frames_from_video(video_path, output_frames_dir, frame_rate=1)  # frame_rate = 30 означает каждый 30-й кадр\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "def load_model_and_processor(model_name):\n",
    "    # Загрузка процессора и модели\n",
    "    processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "    return processor, model\n",
    "\n",
    "# Пример загрузки модели\n",
    "model_name = \"jonatasgrosman/wav2vec2-large-xlsr-53-russian\"\n",
    "processor, model = load_model_and_processor(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nemo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnemo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masr\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnemo_asr\u001b[39;00m\n\u001b[0;32m      2\u001b[0m asr_model \u001b[38;5;241m=\u001b[39m nemo_asr\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mASRModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnvidia/stt_ru_conformer_transducer_large\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m transcriptions \u001b[38;5;241m=\u001b[39m asr_model\u001b[38;5;241m.\u001b[39mtranscribe([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nemo'"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "asr_model = nemo_asr.models.ASRModel.from_pretrained(\"nvidia/stt_ru_conformer_transducer_large\")\n",
    "\n",
    "transcriptions = asr_model.transcribe([\"file.wav\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The model corresponding to this feature extractor: Wav2Vec2FeatureExtractor {\n  \"do_normalize\": true,\n  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n  \"feature_size\": 1,\n  \"padding_side\": \"right\",\n  \"padding_value\": 0.0,\n  \"processor_class\": \"Wav2Vec2ProcessorWithLM\",\n  \"return_attention_mask\": true,\n  \"sampling_rate\": 16000\n}\n was trained using a sampling rate of 16000. Please make sure that the provided `raw_speech` input was sampled with 16000 and not 20000.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m audio_input \u001b[38;5;241m=\u001b[39m load_audio(audio_path)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Преобразуем аудио в тензор нужной формы с указанием частоты дискретизации\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m input_values \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlongest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minput_values\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Модель предсказывает логиты, которые затем преобразуются в текст\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32md:\\dev\\repos\\projects\\hackaton\\.venv\\Lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:95\u001b[0m, in \u001b[0;36mWav2Vec2Processor.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to specify either an `audio` or `text` input to process.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\dev\\repos\\projects\\hackaton\\.venv\\Lib\\site-packages\\transformers\\models\\wav2vec2\\feature_extraction_wav2vec2.py:174\u001b[0m, in \u001b[0;36mWav2Vec2FeatureExtractor.__call__\u001b[1;34m(self, raw_speech, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors, sampling_rate, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampling_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sampling_rate \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate:\n\u001b[1;32m--> 174\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    175\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model corresponding to this feature extractor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was trained using a sampling rate of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please make sure that the provided `raw_speech` input was sampled with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    178\u001b[0m         )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is strongly recommended to pass the ``sampling_rate`` argument to this function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailing to do so can result in silent errors that might be hard to debug.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The model corresponding to this feature extractor: Wav2Vec2FeatureExtractor {\n  \"do_normalize\": true,\n  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n  \"feature_size\": 1,\n  \"padding_side\": \"right\",\n  \"padding_value\": 0.0,\n  \"processor_class\": \"Wav2Vec2ProcessorWithLM\",\n  \"return_attention_mask\": true,\n  \"sampling_rate\": 16000\n}\n was trained using a sampling rate of 16000. Please make sure that the provided `raw_speech` input was sampled with 16000 and not 20000."
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Функция для загрузки аудио и конвертации в формат, пригодный для модели\n",
    "def load_audio(file_path, target_sample_rate=16000):\n",
    "    # Используем pydub для преобразования аудио в моно и нужную частоту дискретизации\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    audio = audio.set_frame_rate(target_sample_rate).set_channels(1)\n",
    "    \n",
    "    # Преобразуем аудио в массив numpy\n",
    "    audio_array = torch.tensor(audio.get_array_of_samples(), dtype=torch.float32) / 2 ** 16 / 2  # нормализация\n",
    "    return audio_array\n",
    "\n",
    "# Загрузка аудиофайла\n",
    "audio_path = \"./audio_files/test_audio.wav\"  # Замените на ваш путь к файлу\n",
    "audio_input = load_audio(audio_path)\n",
    "\n",
    "# Преобразуем аудио в тензор нужной формы с указанием частоты дискретизации\n",
    "input_values = processor(audio_input, return_tensors=\"pt\", padding=\"longest\", sampling_rate=16000).input_values\n",
    "\n",
    "# Модель предсказывает логиты, которые затем преобразуются в текст\n",
    "with torch.no_grad():\n",
    "    logits = model(input_values).logits\n",
    "\n",
    "# Извлекаем предсказания\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Преобразуем предсказания в текст\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "print(\"Transcription:\", transcription)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
